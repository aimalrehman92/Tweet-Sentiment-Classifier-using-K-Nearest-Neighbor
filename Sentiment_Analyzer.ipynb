{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analyzer",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwQA6it3ZspL",
        "colab_type": "text"
      },
      "source": [
        "**Sentiment Analyzer based on Naive Bayes Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg89V9tHn_Z8",
        "colab_type": "text"
      },
      "source": [
        "Here we build a Naive Bayes Classifier for sentiment analysis!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXxP2-QyoCYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTB_4dpboMtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3959040e-e08a-4fc6-fcdd-2d0317c892f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9_ase3loq2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2214dd3-733c-4790-c009-c570e2160edd"
      },
      "source": [
        "path_of_data = '/content/drive/\"My Drive\"/\"Sentiment Analysis\"/'\n",
        "\n",
        "!ls {path_of_data}\n",
        "# Can you see the names of th directories? If yes, proceed..."
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweets.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxgi_T2do7m7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omgg9zD9pTMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Sentiment Analysis/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Z8hrz9pBuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(path+\"Tweets.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvdrT0ihpbOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4610eb18-9276-4c4f-d7ba-7bd4ec7af8dc"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@USAirways Is there a phone line to call into ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@united Bag was finally delivered and intact. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>@usairways Thanks to Kevin and team at F38ish ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir Yes, talked to them. FLL says is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0           neutral  @USAirways Is there a phone line to call into ...\n",
              "1          positive  @united Bag was finally delivered and intact. ...\n",
              "2          positive  @usairways Thanks to Kevin and team at F38ish ...\n",
              "3          negative  @AmericanAir Yes, talked to them. FLL says is ...\n",
              "4          negative  @VirginAmerica and it's a really big bad thing..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWoHmRI7pgtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.columns = ['labels', 'column_having_text_of_tweet']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baBqa3stpl9H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bae5aaa9-0733-4b0f-e1cc-0163dc2a94c0"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u08qSSr_pm2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9959d909-1b22-4e42-8e36-4faa585b7a78"
      },
      "source": [
        "data['labels'].value_counts(normalize=True)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    0.626913\n",
              "neutral     0.211680\n",
              "positive    0.161407\n",
              "Name: labels, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXuNAqAqp0LQ",
        "colab_type": "text"
      },
      "source": [
        "This is the distribution of the label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEd1kJJWp8MR",
        "colab_type": "text"
      },
      "source": [
        "We need to maintain the same distribution when we split it into train and test datasets. This is called Stratified Sampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNktRS3Xp_iE",
        "colab_type": "text"
      },
      "source": [
        "**Train-Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R-PTMHwpzHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "55905ad9-d136-45eb-d420-1584867409f5"
      },
      "source": [
        "# Randomize the dataset\n",
        "data_randomized = data.sample(frac=1, random_state=1)\n",
        "\n",
        "# Calculate index for split\n",
        "training_test_index = round(len(data_randomized) * 0.8) # we are gonna use 80% of the data for training\n",
        "\n",
        "# Training/Test split\n",
        "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
        "test_set = data_randomized[training_test_index:].reset_index(drop=True)\n",
        "\n",
        "print(training_set.shape)\n",
        "print(test_set.shape)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11712, 2)\n",
            "(2928, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b1XaSGEqEor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4947c3e1-6b13-4899-e010-254b14baab22"
      },
      "source": [
        "round(training_set['labels'].value_counts(normalize=True), 2)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    0.63\n",
              "neutral     0.21\n",
              "positive    0.16\n",
              "Name: labels, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXKaui4GqHcs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d854f7d3-75f9-4380-9664-057bd5e795d4"
      },
      "source": [
        "round(test_set['labels'].value_counts(normalize=True), 2)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    0.63\n",
              "neutral     0.21\n",
              "positive    0.16\n",
              "Name: labels, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nudQ4s1qqPbo",
        "colab_type": "text"
      },
      "source": [
        "We will do some cleaning on the training part to bring it into a form that can be used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHHZkR6wqTgB",
        "colab_type": "text"
      },
      "source": [
        "**Data Cleaning on Training part:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2l0RjcXqI4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1b4a87a5-294c-4374-cb05-eb5de735594d"
      },
      "source": [
        "training_set.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>column_having_text_of_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@united 618 was flight out of Houston</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>.@united I think not. I'm not flying you again...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>@SouthwestAir Have had a companion pass for a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir we have 3 more passengers with me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>@SouthwestAir I managed to get sorted out over...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     labels                        column_having_text_of_tweet\n",
              "0   neutral              @united 618 was flight out of Houston\n",
              "1  negative  .@united I think not. I'm not flying you again...\n",
              "2  positive  @SouthwestAir Have had a companion pass for a ...\n",
              "3  negative  @AmericanAir we have 3 more passengers with me...\n",
              "4  positive  @SouthwestAir I managed to get sorted out over..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqn7ptwAqMBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a1327aa9-7826-4e37-b903-71a06c45b4c0"
      },
      "source": [
        "training_set['column_having_text_of_tweet'] = training_set['column_having_text_of_tweet'].str.replace('\\W', ' ')\n",
        "training_set['column_having_text_of_tweet'] = training_set['column_having_text_of_tweet'].str.lower()\n",
        "training_set.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>column_having_text_of_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>united 618 was flight out of houston</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>united i think not  i m not flying you again...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>southwestair have had a companion pass for a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>americanair we have 3 more passengers with me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>southwestair i managed to get sorted out over...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     labels                        column_having_text_of_tweet\n",
              "0   neutral               united 618 was flight out of houston\n",
              "1  negative    united i think not  i m not flying you again...\n",
              "2  positive   southwestair have had a companion pass for a ...\n",
              "3  negative   americanair we have 3 more passengers with me...\n",
              "4  positive   southwestair i managed to get sorted out over..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O9ZcVd-qcVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set['column_having_text_of_tweet'] = training_set['column_having_text_of_tweet'].str.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkUz46I1qg52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = []\n",
        "for tweet in training_set['column_having_text_of_tweet']:\n",
        "    for word in tweet:\n",
        "        vocabulary.append(word)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeIPAUj6qjD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = list(set(vocabulary)) #to obtain only the unique elements"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwBBUTj7qkff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5be76d8-d052-439f-9a9c-6927f84c3ab3"
      },
      "source": [
        "len(vocabulary)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gE3225aqnHI",
        "colab_type": "text"
      },
      "source": [
        "There are 13264 unique words in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH0d-d2nqmFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_counts_per_tweet = {unique_word: [0] * len(training_set['column_having_text_of_tweet']) for unique_word in vocabulary}\n",
        "\n",
        "for index, tweet in enumerate(training_set['column_having_text_of_tweet']):\n",
        "    for word in tweet:\n",
        "        word_counts_per_tweet[word][index] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m87VoVfuqvoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_counts = pd.DataFrame(word_counts_per_tweet) #word_counts is a dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fm3ETuEqyi_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "41ba4b5e-5192-46ef-8068-75aba08071dd"
      },
      "source": [
        "word_counts.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>incurring</th>\n",
              "      <th>purpose</th>\n",
              "      <th>sittin</th>\n",
              "      <th>keambleam</th>\n",
              "      <th>missedupgrades</th>\n",
              "      <th>caren</th>\n",
              "      <th>16mont</th>\n",
              "      <th>epicfail</th>\n",
              "      <th>trained</th>\n",
              "      <th>2uaicfjrms</th>\n",
              "      <th>tim</th>\n",
              "      <th>tore</th>\n",
              "      <th>reuse</th>\n",
              "      <th>warrants</th>\n",
              "      <th>reiterate</th>\n",
              "      <th>mfssh2uhue</th>\n",
              "      <th>clearing</th>\n",
              "      <th>term</th>\n",
              "      <th>complimenting</th>\n",
              "      <th>orlandosentinel</th>\n",
              "      <th>o1u96xc3bo</th>\n",
              "      <th>forgot</th>\n",
              "      <th>jvstatus</th>\n",
              "      <th>cleveland</th>\n",
              "      <th>omaha</th>\n",
              "      <th>interested</th>\n",
              "      <th>zl4bvexmcj</th>\n",
              "      <th>seating</th>\n",
              "      <th>use</th>\n",
              "      <th>rates</th>\n",
              "      <th>7t1rdrcre6</th>\n",
              "      <th>thin</th>\n",
              "      <th>becomes</th>\n",
              "      <th>nogood</th>\n",
              "      <th>statement</th>\n",
              "      <th>medical</th>\n",
              "      <th>t5mrj5yw6i</th>\n",
              "      <th>channels</th>\n",
              "      <th>queue</th>\n",
              "      <th>gettin</th>\n",
              "      <th>...</th>\n",
              "      <th>southwestfail</th>\n",
              "      <th>odds</th>\n",
              "      <th>enforcing</th>\n",
              "      <th>livethelegend</th>\n",
              "      <th>private</th>\n",
              "      <th>threatening</th>\n",
              "      <th>deter</th>\n",
              "      <th>itsaaronchriz</th>\n",
              "      <th>users</th>\n",
              "      <th>matters</th>\n",
              "      <th>future</th>\n",
              "      <th>tiredofthis</th>\n",
              "      <th>verbiage</th>\n",
              "      <th>hn</th>\n",
              "      <th>64kn6geep8</th>\n",
              "      <th>delacy</th>\n",
              "      <th>willie</th>\n",
              "      <th>complaints</th>\n",
              "      <th>staring</th>\n",
              "      <th>belligerent</th>\n",
              "      <th>after2</th>\n",
              "      <th>ifeeldumb</th>\n",
              "      <th>lauderdale</th>\n",
              "      <th>baitandswitch</th>\n",
              "      <th>3hours</th>\n",
              "      <th>kick</th>\n",
              "      <th>street</th>\n",
              "      <th>ua1469</th>\n",
              "      <th>custserv</th>\n",
              "      <th>ujfs9zi6kd</th>\n",
              "      <th>seeing</th>\n",
              "      <th>kosher</th>\n",
              "      <th>neighbors</th>\n",
              "      <th>theft</th>\n",
              "      <th>sympathetic</th>\n",
              "      <th>slight</th>\n",
              "      <th>bankruptcies</th>\n",
              "      <th>3659</th>\n",
              "      <th>777</th>\n",
              "      <th>deactivate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 13264 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   incurring  purpose  sittin  keambleam  ...  bankruptcies  3659  777  deactivate\n",
              "0          0        0       0          0  ...             0     0    0           0\n",
              "1          0        0       0          0  ...             0     0    0           0\n",
              "2          0        0       0          0  ...             0     0    0           0\n",
              "3          0        0       0          0  ...             0     0    0           0\n",
              "4          0        0       0          0  ...             0     0    0           0\n",
              "\n",
              "[5 rows x 13264 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0LvsKesq8pc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5975ed0-501c-4a14-9cca-382e17a01e30"
      },
      "source": [
        "word_counts.shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11712, 13264)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCAeZCmwrK66",
        "colab_type": "text"
      },
      "source": [
        "The above 'shape' command reveals that since there are 11712 tweets in the dataset. Since there are 13264 unique words in this set, the pandas dataframe has the shape 11712 x 13264."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPfqXLD0riwx",
        "colab_type": "text"
      },
      "source": [
        "We will append two more columns to it. The tweet and the label of the sentiment associated to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZn8AzkvrDY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "a8e9a0fe-ae1b-44ed-fb71-52875321514d"
      },
      "source": [
        "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
        "training_set_clean.head()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>column_having_text_of_tweet</th>\n",
              "      <th>incurring</th>\n",
              "      <th>purpose</th>\n",
              "      <th>sittin</th>\n",
              "      <th>keambleam</th>\n",
              "      <th>missedupgrades</th>\n",
              "      <th>caren</th>\n",
              "      <th>16mont</th>\n",
              "      <th>epicfail</th>\n",
              "      <th>trained</th>\n",
              "      <th>2uaicfjrms</th>\n",
              "      <th>tim</th>\n",
              "      <th>tore</th>\n",
              "      <th>reuse</th>\n",
              "      <th>warrants</th>\n",
              "      <th>reiterate</th>\n",
              "      <th>mfssh2uhue</th>\n",
              "      <th>clearing</th>\n",
              "      <th>term</th>\n",
              "      <th>complimenting</th>\n",
              "      <th>orlandosentinel</th>\n",
              "      <th>o1u96xc3bo</th>\n",
              "      <th>forgot</th>\n",
              "      <th>jvstatus</th>\n",
              "      <th>cleveland</th>\n",
              "      <th>omaha</th>\n",
              "      <th>interested</th>\n",
              "      <th>zl4bvexmcj</th>\n",
              "      <th>seating</th>\n",
              "      <th>use</th>\n",
              "      <th>rates</th>\n",
              "      <th>7t1rdrcre6</th>\n",
              "      <th>thin</th>\n",
              "      <th>becomes</th>\n",
              "      <th>nogood</th>\n",
              "      <th>statement</th>\n",
              "      <th>medical</th>\n",
              "      <th>t5mrj5yw6i</th>\n",
              "      <th>channels</th>\n",
              "      <th>...</th>\n",
              "      <th>southwestfail</th>\n",
              "      <th>odds</th>\n",
              "      <th>enforcing</th>\n",
              "      <th>livethelegend</th>\n",
              "      <th>private</th>\n",
              "      <th>threatening</th>\n",
              "      <th>deter</th>\n",
              "      <th>itsaaronchriz</th>\n",
              "      <th>users</th>\n",
              "      <th>matters</th>\n",
              "      <th>future</th>\n",
              "      <th>tiredofthis</th>\n",
              "      <th>verbiage</th>\n",
              "      <th>hn</th>\n",
              "      <th>64kn6geep8</th>\n",
              "      <th>delacy</th>\n",
              "      <th>willie</th>\n",
              "      <th>complaints</th>\n",
              "      <th>staring</th>\n",
              "      <th>belligerent</th>\n",
              "      <th>after2</th>\n",
              "      <th>ifeeldumb</th>\n",
              "      <th>lauderdale</th>\n",
              "      <th>baitandswitch</th>\n",
              "      <th>3hours</th>\n",
              "      <th>kick</th>\n",
              "      <th>street</th>\n",
              "      <th>ua1469</th>\n",
              "      <th>custserv</th>\n",
              "      <th>ujfs9zi6kd</th>\n",
              "      <th>seeing</th>\n",
              "      <th>kosher</th>\n",
              "      <th>neighbors</th>\n",
              "      <th>theft</th>\n",
              "      <th>sympathetic</th>\n",
              "      <th>slight</th>\n",
              "      <th>bankruptcies</th>\n",
              "      <th>3659</th>\n",
              "      <th>777</th>\n",
              "      <th>deactivate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>[united, 618, was, flight, out, of, houston]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>[united, i, think, not, i, m, not, flying, you...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>[southwestair, have, had, a, companion, pass, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>[americanair, we, have, 3, more, passengers, w...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>[southwestair, i, managed, to, get, sorted, ou...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 13266 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     labels                        column_having_text_of_tweet  ...  777  deactivate\n",
              "0   neutral       [united, 618, was, flight, out, of, houston]  ...    0           0\n",
              "1  negative  [united, i, think, not, i, m, not, flying, you...  ...    0           0\n",
              "2  positive  [southwestair, have, had, a, companion, pass, ...  ...    0           0\n",
              "3  negative  [americanair, we, have, 3, more, passengers, w...  ...    0           0\n",
              "4  positive  [southwestair, i, managed, to, get, sorted, ou...  ...    0           0\n",
              "\n",
              "[5 rows x 13266 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QljQqEJat9o1",
        "colab_type": "text"
      },
      "source": [
        "The Naive Bayes algorithm will need to answer the three probability questions to be able to classify new tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94JcN_rFrqaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### Isolating tweets of different sentiments first\n",
        "positive_tweets = training_set_clean[training_set_clean['labels'] == 'positive']\n",
        "negative_tweets = training_set_clean[training_set_clean['labels'] == 'negative']\n",
        "neutral_tweets = training_set_clean[training_set_clean['labels'] == 'neutral']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G87xUQQCuaz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### P(Positive) and P(Negative)\n",
        "p_positive = len(positive_tweets) / len(training_set_clean)\n",
        "p_negative = len(negative_tweets) / len(training_set_clean)\n",
        "p_neutral = len(neutral_tweets) / len(training_set_clean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSd3RQIZudu1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f291369-2954-4fe2-8e4d-b888ddeb524b"
      },
      "source": [
        "p_positive, p_negative, p_neutral"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.16205601092896174, 0.6257684426229508, 0.21217554644808742)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To7u8Ir6vAy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### N_Positive\n",
        "n_words_per_positive_tweets = positive_tweets['column_having_text_of_tweet'].apply(len)\n",
        "n_positive = n_words_per_positive_tweets.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhPuveS8vqpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### N_Negative\n",
        "n_words_per_negative_tweets = negative_tweets['column_having_text_of_tweet'].apply(len)\n",
        "n_negative = n_words_per_negative_tweets.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmAebp6l5pUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### N_Neutral\n",
        "n_words_per_neutral_tweets = neutral_tweets['column_having_text_of_tweet'].apply(len)\n",
        "n_neutral = n_words_per_neutral_tweets.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnDok9-pv0Xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### N_Vocabulary\n",
        "n_vocabulary = len(vocabulary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE2b8-Pxv38D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### Laplace smoothing\n",
        "alpha = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6IZZXgY887c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72ad1109-d08e-4b55-fc16-b4946efa51c2"
      },
      "source": [
        "n_positive, n_negative, n_neutral, n_vocabulary"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27457, 149510, 38079, 13264)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKU7TCkt5zp8",
        "colab_type": "text"
      },
      "source": [
        "Whatever we computed above, serves as \"constant\" in the Naive Bayes Algorithm's equation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjCqXFrPv7pX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initiate parameters\n",
        "parameters_positive = {unique_word:0 for unique_word in vocabulary}\n",
        "parameters_negative = {unique_word:0 for unique_word in vocabulary}\n",
        "parameters_neutral = {unique_word:0 for unique_word in vocabulary}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9TVFhcP5hqA",
        "colab_type": "text"
      },
      "source": [
        "Now, we will make calculations for these parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddF0BYtW5NYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate parameters\n",
        "for word in vocabulary:\n",
        "  \n",
        "  n_word_given_positive = int(positive_tweets[word].sum())   # positive tweets already defined in a cell above\n",
        "  p_word_given_positive = (n_word_given_positive + alpha) / (n_positive + alpha*n_vocabulary)\n",
        "  parameters_positive[word] = p_word_given_positive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mea9ILI5OBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for word in vocabulary:\n",
        "  n_word_given_negative = negative_tweets[word].sum()   # negative tweets already defined in a cell above\n",
        "  p_word_given_negative = (n_word_given_negative + alpha) / (n_negative + alpha*n_vocabulary)\n",
        "  parameters_negative[word] = p_word_given_negative\n",
        "\n",
        "  n_word_given_neutral = neutral_tweets[word].sum()   # neutral tweets already defined in a cell above\n",
        "  p_word_given_neutral = (n_word_given_neutral + alpha) / (n_neutral + alpha*n_vocabulary)\n",
        "  parameters_neutral[word] = p_word_given_neutral"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8_97DxWfADh",
        "colab_type": "text"
      },
      "source": [
        "Apparently, the parameters are calculated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki8y42FxfLYq",
        "colab_type": "text"
      },
      "source": [
        "Let's try the classifier now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8m4Kv8He8zW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def classify(a_tweet):\n",
        "    '''\n",
        "    a_tweet: a string\n",
        "    '''\n",
        "    \n",
        "    a_tweet = re.sub('\\W', ' ', a_tweet)\n",
        "    a_tweet = a_tweet.lower().split()\n",
        "    \n",
        "    p_positive_given_a_tweet = p_positive\n",
        "    p_negative_given_a_tweet = p_negative\n",
        "    p_neutral_given_a_tweet = p_neutral\n",
        "\n",
        "    for word in a_tweet:\n",
        "        if word in parameters_positive:\n",
        "            p_positive_given_a_tweet *= parameters_positive[word]\n",
        "            \n",
        "        if word in parameters_negative:\n",
        "            p_negative_given_a_tweet *= parameters_negative[word]\n",
        "            \n",
        "        if word in parameters_neutral:\n",
        "            p_neutral_given_a_tweet *= parameters_neutral[word]\n",
        "    \n",
        "    \n",
        "    total_p = p_positive_given_a_tweet + p_negative_given_a_tweet + p_neutral_given_a_tweet\n",
        "\n",
        "    p_positive_given_a_tweet = p_positive_given_a_tweet/total_p\n",
        "    p_negative_given_a_tweet = p_negative_given_a_tweet/total_p\n",
        "    p_neutral_given_a_tweet = p_neutral_given_a_tweet/total_p\n",
        "\n",
        "    \n",
        "    #classes = ['p_positive_given_a_tweet', 'p_negative_given_a_tweet', 'p_neutral_given_a_tweet']\n",
        "    class_probs = [p_positive_given_a_tweet, p_negative_given_a_tweet, p_neutral_given_a_tweet]\n",
        "    max_value = max(class_probs)\n",
        "    index_ = class_probs.index(max_value)\n",
        "    \n",
        "    if index_ == 0:\n",
        "      return 'positive'\n",
        "\n",
        "    elif index_ == 1:\n",
        "      return 'negative'\n",
        "\n",
        "    elif index_ == 2:\n",
        "      return 'neutral'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6Rwu0ETh2-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b484f66b-b885-4132-ed8f-8f65e9cfcb9d"
      },
      "source": [
        "senti_ =classify('I love you very very much')\n",
        "senti_"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2tH54_Ryxkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66ca40ea-037f-473d-d11d-497082399ec7"
      },
      "source": [
        "senti_ = classify('I hate you very very much')\n",
        "senti_"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obF3X6Jxy1sl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2f1171e-7620-4763-e85c-39300a6403a4"
      },
      "source": [
        "senti_ = classify('Please follow back')\n",
        "senti_"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neutral'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYsCW4i0kUOK",
        "colab_type": "text"
      },
      "source": [
        "Let's see the results on the test set now !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HCuWo-th7xK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentiments = []\n",
        "for tweet in test_set['column_having_text_of_tweet']:\n",
        "  senti = classify(tweet)\n",
        "  test_sentiments.append(senti)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03PJpgNrz6v3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Orginal sentiments or labels on the test set:\n",
        "\n",
        "original_sentiments = list(test_set['labels'])\n",
        "test_set_len = len(original_sentiments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkQOU3ps1OV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accuracy:\n",
        "\n",
        "indicators = [1 for i, j in zip(test_sentiments, original_sentiments) if i == j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2iyefni21Bb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b05287ae-3297-42f2-de12-76c5620c9fbb"
      },
      "source": [
        "print(\"Accuracy on test set: \"+str(round(len(indicators)/test_set_len*100))+\"%\")"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 77%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-IwUQZQAqbA",
        "colab_type": "text"
      },
      "source": [
        "**Confusion matrix for Positive class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSqEq7ESEb_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from operator import itemgetter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz2EFvFV2-kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#indices where 'positive' sentiment is the label\n",
        "index_positive_GT = [i for i in range(test_set_len) if original_sentiments[i] == 'positive']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG45eFr_ApZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "50aece58-000f-4c70-f8fb-17abb8e3ee02"
      },
      "source": [
        "\n",
        "items_at_those_indices = list(itemgetter(*index_positive_GT)(test_sentiments))\n",
        "TP = items_at_those_indices.count('positive')\n",
        "print(TP)\n",
        "FN = items_at_those_indices.count('negative') + items_at_those_indices.count('neutral')\n",
        "print(FN)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "239\n",
            "226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orSS-l2RBKWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_negative_GT = [i for i in range(test_set_len) if original_sentiments[i] != 'positive']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a65sXqSQESaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2322b3a7-3cbb-4ebf-8efa-c522684323da"
      },
      "source": [
        "\n",
        "items_at_those_indices = list(itemgetter(*index_positive_GT)(test_sentiments))\n",
        "FP = items_at_those_indices.count('positive')\n",
        "print(FP)\n",
        "TN = items_at_those_indices.count('negative') + items_at_those_indices.count('neutral')\n",
        "print(TN)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "239\n",
            "226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQZzj_t7Gq8R",
        "colab_type": "text"
      },
      "source": [
        "**Confusion matrix for every class:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhH1zciKFDnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = list(set(data['labels'])) #classes or sentiments of tweets in the dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvVfjWtXHOLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Obtain_Confusion_Matrix(class_):\n",
        "\n",
        "  index_class_GT = [i for i in range(test_set_len) if original_sentiments[i] == class_]\n",
        "  #indices in the list of original labels where the class holds\n",
        "  items_at_those_indices = list(itemgetter(*index_class_GT)(test_sentiments))\n",
        "  #predictions at those items in the list of predictions\n",
        "  TP = items_at_those_indices.count(class_) #True Positives of that class\n",
        "  #print(\"True Positives: \"+str(TP))\n",
        "  FN = len(items_at_those_indices) - TP #If not TP, they are then False Negatives\n",
        "  #print(\"False Negatives: \"+str(FN))\n",
        "\n",
        "  actual_P = [FN, TP]\n",
        "\n",
        "  index_not_class_GT = [i for i in range(test_set_len) if original_sentiments[i] != class_]\n",
        "  #indices in the list of original labels where the class does not hold\n",
        "  items_at_those_indices = list(itemgetter(*index_not_class_GT)(test_sentiments))\n",
        "  #predictions at those items in the list of predictions\n",
        "  FP = items_at_those_indices.count(class_) #Flase Positives of that class\n",
        "  #print(\"False Positives: \"+str(FP))\n",
        "  TN = len(items_at_those_indices) - FP #If not FP, they are then True Negatives\n",
        "  #print(\"False Negatives: \"+str(TN))\n",
        "\n",
        "  actual_N = [TN, FP]\n",
        "  \n",
        "  conf_matrix = np.array([actual_N, actual_P])\n",
        "  \n",
        "  return conf_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qBATy0GaMKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0e0a001f-cbab-4614-9ec9-deb1004cc943"
      },
      "source": [
        "cf = {}\n",
        "for class_ in classes:\n",
        "  print(\"Obtaining the confusion matrix for the class: \"+class_)\n",
        "  cf[class_] = Obtain_Confusion_Matrix(class_)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining the confusion matrix for the class: negative\n",
            "Obtaining the confusion matrix for the class: neutral\n",
            "Obtaining the confusion matrix for the class: positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY9O1MXGTjDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "176cc222-4025-4c70-e1f1-0f72e30b3150"
      },
      "source": [
        "# For every class, we will compute performance metric from confusion matrix of that class\n",
        "\n",
        "Accu_list = []\n",
        "Rec_list = []\n",
        "Prec_list = []\n",
        "F1_list = []\n",
        "\n",
        "for class_ in classes:\n",
        "  matrix = cf[class_]\n",
        "\n",
        "  print(\"Sentiment : \"+class_)\n",
        "  Accu = (matrix[0][0] + matrix[1][1]) / sum(sum(matrix))\n",
        "  Accu_list.append(Accu)\n",
        "  print(\"Accuracy: \"+str(round(Accu, 2)))\n",
        "\n",
        "  Rec = matrix[1][1] / sum(matrix[1])\n",
        "  Rec_list.append(Rec)\n",
        "  print(\"Recall: \"+str(round(Rec, 2)))\n",
        "\n",
        "  Prec = matrix[1][1] / sum(matrix.T[1])\n",
        "  Prec_list.append(Prec)\n",
        "  print(\"Precision: \"+str(round(Prec, 2)))\n",
        "\n",
        "  F1 = 2*(Prec*Rec)/(Prec+Rec)\n",
        "  F1_list.append(F1)\n",
        "  print(\"F1 Score: \"+str(round(F1, 2)))\n",
        "  print(\"\\n\")\n"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment : negative\n",
            "Accuracy: 0.8\n",
            "Recall: 0.97\n",
            "Precision: 0.77\n",
            "F1 Score: 0.86\n",
            "\n",
            "\n",
            "Sentiment : neutral\n",
            "Accuracy: 0.84\n",
            "Recall: 0.38\n",
            "Precision: 0.74\n",
            "F1 Score: 0.51\n",
            "\n",
            "\n",
            "Sentiment : positive\n",
            "Accuracy: 0.9\n",
            "Recall: 0.51\n",
            "Precision: 0.82\n",
            "F1 Score: 0.63\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxMSnXDPXLlb",
        "colab_type": "text"
      },
      "source": [
        "Now, we calculate Macro-Average for all the performance metric above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYyNxqV5V1ce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "34ed8d06-0151-4466-80ca-fc169e884408"
      },
      "source": [
        "Macro_F1 = sum(F1_list)/3\n",
        "Macro_Accu = sum(Accu_list)/3\n",
        "Macro_Rec = sum(Rec_list)/3\n",
        "Macro_Prec = sum(Prec_list)/3\n",
        "\n",
        "print(\"Macro Accuracy: \"+str(round(Macro_Accu, 2)*100)+\"%\")\n",
        "print(\"Macro Recall: \"+str(round(Macro_Rec, 2)*100)+\"%\")\n",
        "print(\"Macro Precision: \"+str(round(Macro_Prec, 2)*100)+\"%\")\n",
        "print(\"Macro F1 score: \"+str(round(Macro_F1, 2)*100)+\"%\")"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Macro Accuracy: 85.0%\n",
            "Macro Recall: 62.0%\n",
            "Macro Precision: 78.0%\n",
            "Macro F1 score: 67.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVb0XyKvZnbt",
        "colab_type": "text"
      },
      "source": [
        "THE END\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}